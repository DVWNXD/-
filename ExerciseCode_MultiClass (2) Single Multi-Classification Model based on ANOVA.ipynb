{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ANOVA 기반 3 Class 구분성 상위 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 특징 불러오기\n",
    "MC_FeatureData = pd.read_csv('./ProcessedData/MC_FeatureData', sep=',', header=None)\n",
    "\n",
    "# 특징 데이터 정상/고장1/고장2 분리\n",
    "NoOfData = int(MC_FeatureData.shape[1]/3)\n",
    "Normal_FeatureData    = MC_FeatureData.iloc[ : ,            :   NoOfData ]\n",
    "Abnormal1_FeatureData = MC_FeatureData.iloc[ : ,   NoOfData : 2*NoOfData ]\n",
    "Abnormal2_FeatureData = MC_FeatureData.iloc[ : , 2*NoOfData :            ]\n",
    "\n",
    "print(Normal_FeatureData.shape, Abnormal1_FeatureData.shape, Abnormal2_FeatureData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA 기반 구분성 상위 특징값 선택\n",
    "NoOfData = 180\n",
    "MC_P_value_Rank = pd.read_csv('./ProcessedData/MC_P_value_Rank_ANOVA', sep = ',', header=None)\n",
    "Rank = 30 #구분성이 높은 3개짜리\n",
    "\n",
    "Normal    = np.zeros((Rank,NoOfData))\n",
    "Abnormal1 = np.zeros((Rank,NoOfData))\n",
    "Abnormal2 = np.zeros((Rank,NoOfData))\n",
    "\n",
    "for i in range(Rank):\n",
    "    \n",
    "    index          = int(MC_P_value_Rank.iloc[i,0])\n",
    "    Normal[i,:]    = Normal_FeatureData.iloc[index,:].values\n",
    "    Abnormal1[i,:] = Abnormal1_FeatureData.iloc[index,:].values\n",
    "    Abnormal2[i,:] = Abnormal2_FeatureData.iloc[index,:].values\n",
    "\n",
    "# 정상, 고장 특징값 합치기    \n",
    "MC_FeatureSelected = pd.DataFrame(np.concatenate([Normal, Abnormal1, Abnormal2] , axis=1))\n",
    "\n",
    "print(\"Selected Feature Data Size :\", MC_FeatureSelected.shape)\n",
    "print(\"= 데이터 %d개(정상/고장1/고장2 각 %d개씩)가 각각 %d개의 최종 선택된 특징값으로 구성됨\"\n",
    "      %(MC_FeatureSelected.shape[1], MC_FeatureSelected.shape[1]/3, MC_FeatureSelected.shape[0]))\n",
    "# 저장\n",
    "path = './ProcessedData/MC_FeatureSelected_ANOVA'\n",
    "MC_FeatureSelected.to_csv(path, sep=',', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습/검증 데이터, 평가 데이터 분할, 레이블 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_FeatureSelected = pd.read_csv('./ProcessedData/MC_FeatureSelected_ANOVA', sep=',', header=None)\n",
    "MC_FeatureSelected = pd.DataFrame(np.transpose(MC_FeatureSelected))\n",
    "\n",
    "NoOfData   = int(MC_FeatureSelected.shape[0]/3)   # 데이터 개수 (정상/고장1/고장2 각각)\n",
    "FeatNo     = int(MC_FeatureSelected.shape[1])     # 데이터 특징 수 (=데이터 차원)\n",
    "\n",
    "# 분할: 학습+검증 160, 평가 20개!\n",
    "NormalSet    = np.array(MC_FeatureSelected.iloc[            :   NoOfData , :])\n",
    "Abnormal1Set = np.array(MC_FeatureSelected.iloc[   NoOfData : 2*NoOfData , :])\n",
    "Abnormal2Set = np.array(MC_FeatureSelected.iloc[ 2*NoOfData :            , :])\n",
    "\n",
    "FeatureSelected_Reshaped = pd.DataFrame(np.concatenate([NormalSet, Abnormal1Set, Abnormal2Set] , axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Valid_Data =  FeatureSelected_Reshaped.iloc[:-20, :] # 학습/검증데이터\n",
    "temp_Test_Data = FeatureSelected_Reshaped.iloc[-20:, :]    \n",
    "Test_Data = pd.DataFrame(np.concatenate([temp_Test_Data.iloc[:,        :FeatNo  ],\n",
    "                                         temp_Test_Data.iloc[:,  FeatNo:2*FeatNo],\n",
    "                                         temp_Test_Data.iloc[:,2*FeatNo:        ]], axis = 0))\n",
    "Test_Data.shape # 평가 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoOfTrainData = Train_Valid_Data.shape[0]\n",
    "Fold          = 5                                 # Fold 개수 선정 : 데이터 개수의 약수여야 함.\n",
    "FoldDataNo    = int(NoOfTrainData/Fold)           # 1개 Fold 당 (검증)데이터 개수\n",
    "\n",
    "# Validation Data set\n",
    "for i in range(Fold):\n",
    "    \n",
    "    temp_Valid_Normal    = Train_Valid_Data.iloc[FoldDataNo*i : FoldDataNo*(i+1),         :  FeatNo]\n",
    "    temp_Valid_Abnormal1 = Train_Valid_Data.iloc[FoldDataNo*i : FoldDataNo*(i+1),   FeatNo:2*FeatNo]\n",
    "    temp_Valid_Abnormal2 = Train_Valid_Data.iloc[FoldDataNo*i : FoldDataNo*(i+1), 2*FeatNo:        ]\n",
    "    temp_Valid = pd.DataFrame(np.concatenate([temp_Valid_Normal, temp_Valid_Abnormal1, temp_Valid_Abnormal2] , axis=0))\n",
    "    \n",
    "    s = 'Validation_Fold%d = temp_Valid'%(i+1)\n",
    "    exec(s)\n",
    "\n",
    "    \n",
    "# Training Data set\n",
    "for i in range(Fold):\n",
    "    \n",
    "    temp_Train_Front = Train_Valid_Data.iloc[:FoldDataNo*i, :]\n",
    "    temp_Train_Back  = Train_Valid_Data.iloc[FoldDataNo*(i+1):, :]\n",
    "    temp_Train_Total = np.concatenate([temp_Train_Front , temp_Train_Back] , axis=0)\n",
    "    temp_Train_Final = pd.DataFrame(np.concatenate([temp_Train_Total[:,         :  FeatNo],\n",
    "                                                    temp_Train_Total[:,   FeatNo:2*FeatNo],\n",
    "                                                    temp_Train_Total[:, 2*FeatNo:        ]] , axis=0))\n",
    "    \n",
    "    s ='Training_Fold%d  = temp_Train_Final'%(i+1)\n",
    "    exec(s)\n",
    "    \n",
    "# 분할 결과 확인\n",
    "Validation_Fold1.shape, Training_Fold1.shape #560개 중에서 20개 평가 32*3=96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 레이블 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoOfLabel_Train = int(Training_Fold1.shape[0]/3)\n",
    "NoOfLabel_Valid = int(Validation_Fold1.shape[0]/3)\n",
    "NoOfLabel_Test  = int(Test_Data.shape[0]/3)\n",
    "NoOfLabel_Train, NoOfLabel_Valid, NoOfLabel_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label : Label encoding(KNN, SVM)\n",
    "TrainingFold_Label   = np.zeros(3*NoOfLabel_Train , dtype=int)\n",
    "ValidationFold_Label = np.zeros(3*NoOfLabel_Valid , dtype=int)\n",
    "Test_Label           = np.zeros(3*NoOfLabel_Test  , dtype=int)\n",
    "# 고장1, 고장2 데이터(학습용) Label 값 = 1,2\n",
    "TrainingFold_Label[  NoOfLabel_Train:2*NoOfLabel_Train] = 1\n",
    "TrainingFold_Label[2*NoOfLabel_Train:                 ] = 2\n",
    "# 고장1, 고장2 데이터(검증용) Label 값 = 1,2\n",
    "ValidationFold_Label[  NoOfLabel_Valid:2*NoOfLabel_Valid] = 1\n",
    "ValidationFold_Label[2*NoOfLabel_Valid:                 ] = 2\n",
    "# 고장1, 고장2 데이터(평가용) Label 값 = 1,2\n",
    "Test_Label[  NoOfLabel_Test:2*NoOfLabel_Test] = 1\n",
    "Test_Label[2*NoOfLabel_Test:                ] = 2\n",
    "\n",
    "TrainingFold_Label   = pd.Series(TrainingFold_Label)\n",
    "ValidationFold_Label = pd.Series(ValidationFold_Label)\n",
    "Test_Label           = pd.Series(Test_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingFold_Label_forANN   = np.zeros((NoOfLabel_Train*3,3) , dtype=int)\n",
    "ValidationFold_Label_forANN = np.zeros((NoOfLabel_Valid*3,3) , dtype=int)\n",
    "Test_Label_forANN           = np.zeros((NoOfLabel_Test *3,3) , dtype=int)\n",
    "# 정상, 고장1, 고장2 데이터 Label = [1,0,0], [0,1,0], [0,0,1]\n",
    "TrainingFold_Label_forANN[                 :  NoOfLabel_Train, 0] = 1\n",
    "TrainingFold_Label_forANN[  NoOfLabel_Train:2*NoOfLabel_Train, 1] = 1\n",
    "TrainingFold_Label_forANN[2*NoOfLabel_Train:                 , 2] = 1\n",
    "\n",
    "ValidationFold_Label_forANN[                 :  NoOfLabel_Valid, 0] = 1\n",
    "ValidationFold_Label_forANN[  NoOfLabel_Valid:2*NoOfLabel_Valid, 1] = 1\n",
    "ValidationFold_Label_forANN[2*NoOfLabel_Valid:                 , 2] = 1\n",
    "\n",
    "Test_Label_forANN[                :  NoOfLabel_Test, 0] = 1\n",
    "Test_Label_forANN[  NoOfLabel_Test:2*NoOfLabel_Test, 1] = 1\n",
    "Test_Label_forANN[2*NoOfLabel_Test:                , 2] = 1\n",
    "\n",
    "TrainingFold_Label_forANN   = pd.DataFrame(TrainingFold_Label_forANN)\n",
    "ValidationFold_Label_forANN = pd.DataFrame(ValidationFold_Label_forANN)\n",
    "Test_Label_forANN           = pd.DataFrame(Test_Label_forANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할 데이터, 레이블 저장\n",
    "for i in range(Fold):\n",
    "    path1 = './K_FoldData/Training_Fold%d'  %(i+1)\n",
    "    path2 = './K_FoldData/Validation_Fold%d'%(i+1)\n",
    "    \n",
    "    c1 = 'Training_Fold%d.to_csv(  path1, sep = \",\", header = None, index = None)'%(i+1)\n",
    "    c2 = 'Validation_Fold%d.to_csv(path2, sep = \",\", header = None, index = None)'%(i+1)\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "Test_Data.to_csv('./K_FoldData/Test_Data', sep = \",\", header = None, index = None)\n",
    "\n",
    "TrainingFold_Label.to_csv(  './K_FoldData/TrainingFold_Label', header = None, index = None)\n",
    "ValidationFold_Label.to_csv('./K_FoldData/ValidationFold_Label', header = None, index = None)\n",
    "Test_Label.to_csv(          './K_FoldData/Test_Label', header = None, index = None)\n",
    "\n",
    "TrainingFold_Label_forANN.to_csv(  './K_FoldData/TrainingFold_Label_forANN', sep = \",\", header = None, index = None)\n",
    "ValidationFold_Label_forANN.to_csv('./K_FoldData/ValidationFold_Label_forANN', sep = \",\", header = None, index = None)\n",
    "Test_Label_forANN.to_csv(          './K_FoldData/Test_Label_forANN', sep = \",\", header = None, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 분할 이전 전체 데이터 및 레이블\n",
    "# Normal_Training_All    = Train_Valid_Data.iloc[:,        :  FeatNo]\n",
    "# Abnormal1_Training_All = Train_Valid_Data.iloc[:,  FeatNo:2*FeatNo]\n",
    "# Abnormal2_Training_All = Train_Valid_Data.iloc[:,2*FeatNo:        ]\n",
    "# Training_All = pd.DataFrame(np.concatenate([Normal_Training_All, Abnormal1_Training_All, Abnormal2_Training_All], axis = 0))\n",
    "\n",
    "# Training_All_Label = np.zeros(NoOfTrainData*3)\n",
    "# Training_All_Label[  NoOfTrainData:2*NoOfTrainData] = 1\n",
    "# Training_All_Label[2*NoOfTrainData:               ] = 2\n",
    "# Training_All_Label = pd.Series(Training_All_Label)\n",
    "\n",
    "# Training_All_Label_forANN = np.zeros((NoOfTrainData*3,3))\n",
    "# Training_All_Label_forANN[               :  NoOfTrainData , 0] = 1\n",
    "# Training_All_Label_forANN[  NoOfTrainData:2*NoOfTrainData , 1] = 1\n",
    "# Training_All_Label_forANN[2*NoOfTrainData:                , 2] = 1\n",
    "# Training_All_Label_forANN = pd.DataFrame(Training_All_Label_forANN)\n",
    "\n",
    "# Training_All.to_csv('./K_FoldData/Training_All', sep = \",\", header = None, index = None)\n",
    "# Training_All_Label.to_csv('./K_FoldData/Training_All_Label', sep = \",\", header = None, index = None)\n",
    "# Training_All_Label_forANN.to_csv('./K_FoldData/Training_All_Label_forANN', sep = \",\", header = None, index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 분류 모델 학습/검증(K-fold 교차검증)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터, 레이블 불러오기\n",
    "# k-fold 학습/검증 데이터\n",
    "for i in range(Fold):\n",
    "    \n",
    "    path1 = './K_FoldData/Training_Fold%d'%(i+1)\n",
    "    path2 = './K_FoldData/Validation_Fold%d'%(i+1)\n",
    "    c1 = 'Training_Fold%d   = np.array(pd.read_csv(path1, sep=\",\", header=None))'%(i+1)\n",
    "    c2 = 'Validation_Fold%d = np.array(pd.read_csv(path2, sep=\",\", header=None))'%(i+1)\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "# K-fold 학습/검증 레이블\n",
    "TrainingFold_Label   = np.array(pd.read_csv('./K_FoldData/TrainingFold_Label'  , sep=\",\", header=None).T.squeeze())\n",
    "ValidationFold_Label = np.array(pd.read_csv('./K_FoldData/ValidationFold_Label', sep=\",\", header=None).T.squeeze())\n",
    "# # 전체 학습용 데이터\n",
    "# Training_All       = np.array(pd.read_csv('./K_FoldData/Training_All', sep = \",\", header = None))\n",
    "# Training_All_Label = np.array(pd.read_csv('./K_FoldData/Training_All_Label', sep = \",\", header = None).T.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold 교차검증\n",
    "Add    = 0\n",
    "Divide = 0\n",
    "\n",
    "for i in range(Fold):\n",
    "    c1 = 'Training_CurrentFold = Training_Fold%d'%(i+1)\n",
    "    exec(c1)\n",
    "    c2 = 'Validation_CurrentFold = Validation_Fold%d'%(i+1)\n",
    "    exec(c2)\n",
    "\n",
    "    knnModel_CurrentFold = KNeighborsClassifier(n_neighbors = 7).fit(Training_CurrentFold , TrainingFold_Label)\n",
    "    \n",
    "    c3 = 'knnscore_Fold%d = knnModel_CurrentFold.score(Validation_CurrentFold , ValidationFold_Label)'%(i+1)\n",
    "    exec(c3)\n",
    "        \n",
    "    Add += knnModel_CurrentFold.score(Validation_CurrentFold, ValidationFold_Label)\n",
    "    Divide += 1\n",
    "    \n",
    "Avg_accuracy = Add/Divide\n",
    "\n",
    "print('[Result of K-fold Cross Validation] \\n')\n",
    "print(' Fold 1: {:.2f}% \\n Fold 2: {:.2f}% \\n Fold 3: {:.2f}% \\n Fold 4: {:.2f}% \\n Fold 5: {:.2f}%'.\n",
    "        format(knnscore_Fold1*100, knnscore_Fold2*100, knnscore_Fold3*100, knnscore_Fold4*100, knnscore_Fold5*100))\n",
    "print('\\n Average accuracy: {:.2f}%'.format(Avg_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold 교차검증\n",
    "Add    = 0\n",
    "Divide = 0\n",
    "\n",
    "for i in range(Fold):\n",
    "    c1 = 'Training_CurrentFold = Training_Fold%d'%(i+1)\n",
    "    exec(c1)\n",
    "    c2 = 'Validation_CurrentFold = Validation_Fold%d'%(i+1)\n",
    "    exec(c2)\n",
    "\n",
    "    svmModel_CurrentFold = SVC(kernel = 'linear').fit(Training_CurrentFold , TrainingFold_Label)\n",
    "    \n",
    "    c3 = 'svmscore_Fold%d = svmModel_CurrentFold.score(Validation_CurrentFold , ValidationFold_Label)'%(i+1)\n",
    "    exec(c3)\n",
    "        \n",
    "    Add += svmModel_CurrentFold.score(Validation_CurrentFold, ValidationFold_Label)\n",
    "    Divide += 1\n",
    "    \n",
    "Avg_accuracy = Add/Divide\n",
    "\n",
    "print('[Result of K-fold Cross Validation] \\n')\n",
    "print(' Fold 1: {:.2f}% \\n Fold 2: {:.2f}% \\n Fold 3: {:.2f}% \\n Fold 4: {:.2f}% \\n Fold 5: {:.2f}%'.\n",
    "        format(svmscore_Fold1*100, svmscore_Fold2*100, svmscore_Fold3*100, svmscore_Fold4*100, svmscore_Fold5*100))\n",
    "print('\\n Average accuracy: {:.2f}%'.format(Avg_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = 5\n",
    "\n",
    "# k-fold 학습/검증 데이터\n",
    "for i in range(Fold):\n",
    "    \n",
    "    path1 = './K_FoldData/Training_Fold%d'%(i+1)\n",
    "    path2 = './K_FoldData/Validation_Fold%d'%(i+1)\n",
    "    c1 = 'Training_Fold%d   = np.array(pd.read_csv(path1, sep=\",\", header=None))'%(i+1)\n",
    "    c2 = 'Validation_Fold%d = np.array(pd.read_csv(path2, sep=\",\", header=None))'%(i+1)\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "# K-fold 학습/검증 레이블\n",
    "TrainingFold_Label   = np.array(pd.read_csv('./K_FoldData/TrainingFold_Label_forANN'  , sep=\",\", header=None))\n",
    "ValidationFold_Label = np.array(pd.read_csv('./K_FoldData/ValidationFold_Label_forANN', sep=\",\", header=None))\n",
    "# # 전체 학습용 데이터\n",
    "# Training_All       = np.array(pd.read_csv('./K_FoldData/Training_All', sep = \",\", header = None))\n",
    "# Training_All_Label = np.array(pd.read_csv('./K_FoldData/Training_All_Label_forANN', sep = \",\", header = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate  = 0.0001\n",
    "noOfNeuron    = 16\n",
    "iteration     = 2000\n",
    "\n",
    "def ANN_model(input_data):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units = noOfNeuron, input_shape = (input_data.shape[1],) ))  # Input  Layer\n",
    "    model.add(keras.layers.Dense(units = noOfNeuron, activation = keras.activations.relu))    # Hidden Layer 1\n",
    "    model.add(keras.layers.Dense(units = noOfNeuron, activation = keras.activations.relu))    # Hidden Layer 2\n",
    "    model.add(keras.layers.Dense(units = 3,          activation = keras.activations.softmax)) # Output Layer\n",
    "    #레이블이 3차원이라서 units이 3개\n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label        = TrainingFold_Label\n",
    "Label_Val    = ValidationFold_Label\n",
    "Accuracy_sum = 0\n",
    "\n",
    "print('[Result of K-fold Cross Validation] \\n')\n",
    "\n",
    "for i in range(Fold):\n",
    "    tf.random.set_seed(777)\n",
    "    \n",
    "    s1= 'Data     = Training_Fold%d'  %(i+1)\n",
    "    s2= 'Data_Val = Validation_Fold%d'%(i+1)\n",
    "    exec(s1)\n",
    "    exec(s2)\n",
    "    \n",
    "    model = ANN_model(Data)\n",
    "    # train model\n",
    "    hist = model.fit(Data, Label, epochs=iteration, verbose = 0)\n",
    "    Loss, Accuracy = model.evaluate(Data_Val,  Label_Val, verbose=0)\n",
    "    Accuracy_sum = Accuracy_sum + Accuracy\n",
    "    print('Fold {}: {:.2f}%'.format((i+1), Accuracy*100))\n",
    "\n",
    "print('* Average accuracy : {:.2f}%'.format((Accuracy_sum/Fold)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 최적화 코드가 없어서 한번 해보면 좋을듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
