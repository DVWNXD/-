{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',    100)      # DataFrame 데이터 확인 시 최대 표시 행 수\n",
    "pd.set_option('display.max_columns', 100)      # DataFrame 데이터 확인 시 최대 표시 열 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__                         # tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow v1 기능만 사용 (v2 기능 강제 차단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samsung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior() #v2 기능 강제 차단\n",
    "tf.set_random_seed(777)  # 결과 재현성을 위하여 난수 시드 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 30)\n",
      "(64, 30)\n",
      "(256, 2)\n",
      "(64, 2)\n",
      "(320, 30)\n"
     ]
    }
   ],
   "source": [
    "Fold = 5\n",
    "\n",
    "# k-fold 학습/검증 데이터\n",
    "for i in range(Fold):\n",
    "    \n",
    "    path1 = './K_FoldData/Training_Fold%d'%(i+1)\n",
    "    path2 = './K_FoldData/Validation_Fold%d'%(i+1)\n",
    "    c1 = 'Training_Fold%d   = np.array(pd.read_csv(path1, sep=\",\", header=None))'%(i+1)\n",
    "    c2 = 'Validation_Fold%d = np.array(pd.read_csv(path2, sep=\",\", header=None))'%(i+1)\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "\n",
    "# K-fold 학습/검증 레이블\n",
    "TrainingFold_Label   = np.array(pd.read_csv('./K_FoldData/TrainingFold_Label_forANN'  , sep=\",\", header=None))\n",
    "ValidationFold_Label = np.array(pd.read_csv('./K_FoldData/ValidationFold_Label_forANN', sep=\",\", header=None))\n",
    "    \n",
    "    \n",
    "# 전체 학습용 데이터\n",
    "Training_All       = np.array(pd.read_csv('./K_FoldData/Training_All', sep = \",\", header = None))\n",
    "Training_All_Label = np.array(pd.read_csv('./K_FoldData/Training_All_Label_forANN', sep = \",\", header = None))\n",
    "\n",
    "print(Training_Fold1.shape)\n",
    "print(Validation_Fold1.shape)\n",
    "print(TrainingFold_Label.shape)\n",
    "print(ValidationFold_Label.shape)\n",
    "print(Training_All.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN(Artificial Neural Network) hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate  = 0.0001\n",
    "noOfNeuron    = 16 #레이어당 뉴런수\n",
    "iteration     = 5000\n",
    "#act_func = relu, sigmoid 이런 파라미터도 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN 구조(Architecture) 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, Training_Fold1.shape[1]]) # 데이터 타입 정의, 몇개의 데이터가 들어올건지 여기서는 30개\n",
    "Y = tf.placeholder(tf.float32, [None, 2]) # one hot encoding 으로 지정해서 2차원으로 만듬\n",
    "\n",
    "# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing 모델의 과적합 방지를 위해 한번 이터레이션이 돌때 비활성화되는 뉴런을 줄인다\n",
    "# keep_prob = tf.placeholder(tf.float32)                                                       이런 기법이 있다 정도만\n",
    "\n",
    "# weights & bias for nn layers\n",
    "\n",
    "# Input Layer\n",
    "W1 = tf.Variable(tf.random_normal([Training_Fold1.shape[1], noOfNeuron])) #30개 16개\n",
    "b1 = tf.Variable(tf.random_normal([noOfNeuron])) #뉴런의 바이어스만금만\n",
    "L1 = tf.matmul(X, W1) + b1 #인풋값과 생성된 weight값들을 곱해주고 바이어스를 더해주면 인풋레이어의 아웃풋이 나옴\n",
    "\n",
    "# Hidden Layer 1\n",
    "W2 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron])) #첫번째 레이어 뉴런의 개수가 인풋 두번째 레이어의 뉴런의 개수\n",
    "b2 = tf.Variable(tf.random_normal([noOfNeuron])) #뉴런 하나마다 가지고 있는 가중치\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2) #인풋레이어의 아웃풋에 가중치 곱해주고 바이어스 더해줌 그리고 액티베이션 펑션 적용 \n",
    "\n",
    "# Hidden Layer 2\n",
    "W3 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b3 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3) #은닉층 2개 통과한 output\n",
    "\n",
    "# Output Layer\n",
    "W4 = tf.Variable(tf.random_normal([noOfNeuron, 2]))\n",
    "b4 = tf.Variable(tf.random_normal([2]))\n",
    "hypothesis = tf.matmul(L3, W4) + b4 #최종 output\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y)) #비용함수 정의 hypothesis 평균이 최소화 되는거\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost) #아담 옵티마이저를 사용, 학습률 지정, 코스트값 집어 넣는다\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN(Neural Network) 학습 및 평가 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 500th iteration: 1.3772462606430054\n",
      "Cost at 1000th iteration: 1.2566884756088257\n",
      "Cost at 1500th iteration: 1.0911749601364136\n",
      "Cost at 2000th iteration: 0.9011598825454712\n",
      "Cost at 2500th iteration: 0.6582923531532288\n",
      "Cost at 3000th iteration: 0.43442022800445557\n",
      "Cost at 3500th iteration: 0.29074928164482117\n",
      "Cost at 4000th iteration: 0.1346479207277298\n",
      "Cost at 4500th iteration: 0.0911049172282219\n",
      "Cost at 5000th iteration: 0.07932459563016891\n",
      "Fold 1 Validation Acc: 95.31%\n"
     ]
    }
   ],
   "source": [
    "Data      = Training_Fold1 \n",
    "Data_Val  = Validation_Fold1\n",
    "Label     = TrainingFold_Label\n",
    "Label_Val = ValidationFold_Label\n",
    "#학습, 검즘, 레이블 불러옴\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) #전역변수 초기화\n",
    "\n",
    "for step in range(1, iteration+1):\n",
    "    c, o = sess.run([cost, optimizer], feed_dict = {X : Data, Y: Label}) #run함수를 통해\n",
    "    if step % 500 == 0:\n",
    "        print('Cost at {}th iteration: {}'.format(step, c))\n",
    "\n",
    "Validation_Acc_Fold1= sess.run(accuracy, feed_dict={X : Data_Val, Y: Label_Val})\n",
    "print('Fold 1 Validation Acc: {:.2f}%'.format(Validation_Acc_Fold1*100))\n",
    "\n",
    "sess.close() #반복됨에 따라 cost낮아짐 정확도는 95.31%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN(Neural Network) 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result of K-fold Cross Validation] \n",
      "\n",
      "Fold 1: 95.31%\n",
      "Fold 2: 95.31%\n",
      "Fold 3: 100.00%\n",
      "Fold 4: 96.88%\n",
      "Fold 5: 100.00%\n",
      "* Average accuracy : 97.50%\n"
     ]
    }
   ],
   "source": [
    "Label     = TrainingFold_Label\n",
    "Label_Val = ValidationFold_Label\n",
    "Accuracy_sum = 0\n",
    "\n",
    "print('[Result of K-fold Cross Validation] \\n')\n",
    "\n",
    "for i in range(Fold):\n",
    "    \n",
    "    s1= 'Data     = Training_Fold%d'  %(i+1)\n",
    "    s2= 'Data_Val = Validation_Fold%d'%(i+1)\n",
    "    exec(s1)\n",
    "    exec(s2)\n",
    "\n",
    "# train my model\n",
    "# initialize\n",
    "    sess = tf.Session() #폴드돌때 마다 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(1, iteration+1):\n",
    "    \n",
    "        c, o = sess.run([cost, optimizer], feed_dict = {X : Data, Y: Label})\n",
    "        \n",
    "    Accuracy = sess.run(accuracy, feed_dict={X : Data_Val, Y: Label_Val})\n",
    "    Accuracy_sum = Accuracy_sum + Accuracy\n",
    "    \n",
    "    print('Fold {}: {:.2f}%'.format((i+1), Accuracy*100))\n",
    "    sess.close()\n",
    "    \n",
    "print('* Average accuracy : {:.2f}%'.format((Accuracy_sum/Fold)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 학습 데이터로 NN 학습 및 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Training_All\n",
    "y_data = Training_All_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1000\n",
      "   Validation Acc: 94.38%\n",
      "iteration 2000\n",
      "   Validation Acc: 95.00%\n",
      "iteration 3000\n",
      "   Validation Acc: 95.94%\n",
      "iteration 4000\n",
      "   Validation Acc: 97.19%\n",
      "iteration 5000\n",
      "   Validation Acc: 98.44%\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "# initialize\n",
    "sess = tf.Session() #초기화 해줌\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1, iteration+1):\n",
    "    \n",
    "    c, o = sess.run([cost, optimizer], feed_dict = {X : x_data, Y: y_data}) #코스트랑 옴티마이저 동일, x,y데이터로 사용하는거 동일\n",
    "    Acc = sess.run(accuracy, feed_dict={X : x_data, Y: y_data})\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "            \n",
    "        print('iteration {}'.format(step))    \n",
    "        print('   Validation Acc: {:.2f}%'.format(Acc*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./MLmodels/ANN_model_tf1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './MLmodels/ANN_model_tf1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model 불러와서 진단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 그래프 초기화 (아무것도 작성안했을 시 실행 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Graph 지울 때 사용\n",
    "tf.reset_default_graph() #구조를 미리 만들어 놓을걸 지움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, Training_Fold1.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "#동일한 방식으로 구조 선언\n",
    "# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing\n",
    "# keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "\n",
    "# Input Layer\n",
    "W1 = tf.Variable(tf.random_normal([Training_Fold1.shape[1], noOfNeuron]))\n",
    "b1 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L1 = tf.matmul(X, W1) + b1\n",
    "\n",
    "# Hidden Layer 1\n",
    "W2 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b2 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# Hidden Layer 2\n",
    "W3 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b3 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "# Output Layer\n",
    "W4 = tf.Variable(tf.random_normal([noOfNeuron, 2]))\n",
    "b4 = tf.Variable(tf.random_normal([2]))\n",
    "hypothesis = tf.matmul(L3, W4) + b4\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./MLmodels/ANN_model_tf1\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기 (그래프 파라미터 [Variable w, b] 불러옴)\n",
    "sess  = tf.Session()\n",
    "LoadedModel = tf.train.Saver()\n",
    "LoadedModel.restore(sess, './MLmodels/ANN_model_tf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data  = np.array(pd.read_csv('./K_FoldData/Test_Data' , sep=\",\", header=None))\n",
    "Test_Label = np.array(pd.read_csv('./K_FoldData/Test_Label_forANN', sep=\",\", header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Performance of ANN model] \n",
      "\n",
      "Accuracy : 97.50%\n"
     ]
    }
   ],
   "source": [
    "Accuracy = sess.run(accuracy, feed_dict={X: Test_Data, Y: Test_Label})\n",
    "print('[Performance of ANN model] \\n')\n",
    "print('Accuracy : {:.2f}%'.format(Accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
