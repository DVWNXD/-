{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',    100)      # DataFrame 데이터 확인 시 최대 표시 행 수\n",
    "pd.set_option('display.max_columns', 100)      # DataFrame 데이터 확인 시 최대 표시 열 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(777) #난수 시드 저장하는거 웨이트랑 바이어스 일정하게 해주기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 30)\n",
      "(64, 30)\n",
      "(256, 2)\n",
      "(64, 2)\n",
      "(320, 30)\n"
     ]
    }
   ],
   "source": [
    "Fold = 5\n",
    "\n",
    "# k-fold 학습/검증 데이터\n",
    "for i in range(Fold):\n",
    "    \n",
    "    path1 = './K_FoldData/Training_Fold%d'%(i+1)\n",
    "    path2 = './K_FoldData/Validation_Fold%d'%(i+1)\n",
    "    c1 = 'Training_Fold%d   = np.array(pd.read_csv(path1, sep=\",\", header=None))'%(i+1)\n",
    "    c2 = 'Validation_Fold%d = np.array(pd.read_csv(path2, sep=\",\", header=None))'%(i+1)\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "\n",
    "# K-fold 학습/검증 레이블\n",
    "TrainingFold_Label   = np.array(pd.read_csv('./K_FoldData/TrainingFold_Label_forANN'  , sep=\",\", header=None))\n",
    "ValidationFold_Label = np.array(pd.read_csv('./K_FoldData/ValidationFold_Label_forANN', sep=\",\", header=None))\n",
    "\n",
    "# 전체 학습용 데이터\n",
    "Training_All       = np.array(pd.read_csv('./K_FoldData/Training_All', sep = \",\", header = None))\n",
    "Training_All_Label = np.array(pd.read_csv('./K_FoldData/Training_All_Label_forANN', sep = \",\", header = None))\n",
    "\n",
    "print(Training_Fold1.shape)\n",
    "print(Validation_Fold1.shape)\n",
    "print(TrainingFold_Label.shape)\n",
    "print(ValidationFold_Label.shape)\n",
    "print(Training_All.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN 구조(Architecture) 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(input_data, learningRate, noOfHiddenLayer, noOfNeuron):\n",
    "    model = keras.Sequential() #최적화할 파라미터 넣어줌\n",
    "    model.add(keras.layers.Dense(units = noOfNeuron, input_shape = (input_data.shape[1],) ))   # Input  Layer\n",
    "    for i in range(noOfHiddenLayer):\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron, activation = keras.activations.relu)) # Hidden Layer \n",
    "    model.add(keras.layers.Dense(units = 2,          activation = keras.activations.softmax))  # Output Layer 정상 고장이라 unit=2\n",
    "    \n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(input_data, learningRate, noOfHiddenLayer, noOfNeuron, Hactivation):\n",
    "    model = keras.Sequential() #최적화할 파라미터 넣어줌\n",
    "    Hactivation = [keras.activations.relu, keras.activations.softmax]\n",
    "    model.add(keras.layers.Dense(units = noOfNeuron, input_shape = (input_data.shape[1],) ))   # Input  Layer\n",
    "    for i in range(noOfHiddenLayer):\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron, activation = Hactivation)) # Hidden Layer \n",
    "    model.add(keras.layers.Dense(units = 2,          activation = keras.activations.softmax))  # Output Layer\n",
    "    \n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    return model #활성함수 넣은버전 원래 코드에는 x 수업시간에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 기반 Hyperparameter 별 성능 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 반복문 활용 grid search cv사용한다면 과적합 판단하는 plot불러오는거 어려움 그래서 for문 활용을 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 나오는 시간은 비슷하니까 과적합 방지를 위해 반복문 사용 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F291884C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.0001 2 8 model done.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F291863E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.0001 2 16 model done.\n",
      "0.0001 3 8 model done.\n",
      "0.0001 3 16 model done.\n",
      "0.001 2 8 model done.\n",
      "0.001 2 16 model done.\n",
      "0.001 3 8 model done.\n",
      "0.001 3 16 model done.\n"
     ]
    }
   ],
   "source": [
    "Fold = 5\n",
    "iteration = 500\n",
    "Label        = TrainingFold_Label\n",
    "Label_Val    = ValidationFold_Label\n",
    "\n",
    "# 비교할 하이퍼파라미터들 리스트 형태로 만들기 파라미터 하나당 2개\n",
    "param_learningRate      = [0.0001, 0.001]    # 학습률\n",
    "param_noOfHiddenLayer   = [2, 3]          # 은닉 레이어 수\n",
    "param_noOfNeuron        = [8, 16]         # 레이어 당 뉴런 개수\n",
    "\n",
    "# 파라미터별 정확도 기록할 변수 설정\n",
    "Accuracy_df = pd.DataFrame(np.zeros(shape=(len(param_learningRate)*len(param_noOfHiddenLayer)*len(param_noOfNeuron),4)),\n",
    "                           columns=['LearningRate', 'NoOfHiddenLayer', 'NoOfNeuron', 'Accuracy'])\n",
    "cnt = 0\n",
    "\n",
    "# Grid Search 코드\n",
    "for learningRate in param_learningRate:\n",
    "    \n",
    "    for noOfHiddenLayer in param_noOfHiddenLayer:\n",
    "        \n",
    "        for noOfNeuron in param_noOfNeuron:\n",
    "            \n",
    "            ValidScore = 0 # 모델 바뀔 때마다 검증정확도 변수 초기화\n",
    "            \n",
    "            for i in range(Fold):\n",
    "                c1 = 'Data = Training_Fold%d'%(i+1)\n",
    "                exec(c1)\n",
    "                c2 = 'Data_Val = Validation_Fold%d'%(i+1)\n",
    "                exec(c2)\n",
    "                \n",
    "                model = ANN_model(Data, learningRate, noOfHiddenLayer, noOfNeuron) # 하이퍼파라미터 내부 인자로 지정 ANNmodel함수가 data 플러스 함수라 지난번이랑 다름\n",
    "                tempHist = model.fit(Data, Label, epochs=iteration, verbose = 0)                   # 학습\n",
    "                tempLoss, tempValidScore = model.evaluate(Data_Val,  Label_Val, verbose=0)         # 검증\n",
    "\n",
    "                ValidScore += tempValidScore # Fold 별 검증 정확도 합산 \n",
    "\n",
    "            Acc = ValidScore/Fold # 평균 검증 정확도\n",
    "            Accuracy_df.iloc[cnt, :] = [learningRate, noOfHiddenLayer, noOfNeuron, Acc] # 모델의 하이퍼파라미터\n",
    "            cnt += 1\n",
    "            \n",
    "            print('{} {} {} model done.'.format(learningRate, noOfHiddenLayer, noOfNeuron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LearningRate</th>\n",
       "      <th>NoOfHiddenLayer</th>\n",
       "      <th>NoOfNeuron</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.996875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.993750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.993750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.990625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.990625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.990625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LearningRate  NoOfHiddenLayer  NoOfNeuron  Accuracy\n",
       "5        0.0010              2.0        16.0  0.996875\n",
       "1        0.0001              2.0        16.0  0.993750\n",
       "4        0.0010              2.0         8.0  0.993750\n",
       "3        0.0001              3.0        16.0  0.990625\n",
       "6        0.0010              3.0         8.0  0.990625\n",
       "7        0.0010              3.0        16.0  0.990625\n",
       "0        0.0001              2.0         8.0  0.987500\n",
       "2        0.0001              3.0         8.0  0.912500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_df_sorted = Accuracy_df.sort_values(by = ['Accuracy'], ascending = False) # 성능 확인 내림차순 정리\n",
    "Accuracy_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. sklearn.model_selection.GridSearchCV 함수 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(input_data = Training_Fold1, learningRate = 0.0001, noOfHiddenLayer = 2, noOfNeuron = 8):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units = noOfNeuron, input_shape = (input_data.shape[1],) ))   # Input  Layer\n",
    "    for i in range(noOfHiddenLayer):\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron, activation = keras.activations.relu)) # Hidden Layer \n",
    "    model.add(keras.layers.Dense(units = 2,          activation = keras.activations.softmax))  # Output Layer\n",
    "    \n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier #다른 라이브러리와 호환가능하게 만듬\n",
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IterationForPrintAcc = 100\n",
    "\n",
    "class AccuracyPerEpoch(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keras.callbacks.Callback()\n",
    "        if epoch%IterationForPrintAcc == 0:\n",
    "            print(\"{} Epochs Accuracy : {:.2f}% \".format(epoch, logs[\"accuracy\"]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교할 하이퍼파라미터 사전(Dictionary) 형태로 만들기\n",
    "GridParams = {\n",
    "    'learningRate' : [0.0001, 0.001],\n",
    "    'noOfHiddenLayer' : [2, 3],\n",
    "    'noOfNeuron' : [8, 16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 62.50% \n",
      "300 Epochs Accuracy : 62.50% \n",
      "400 Epochs Accuracy : 62.50% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7863 - accuracy: 0.0469\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 77.73% \n",
      "300 Epochs Accuracy : 94.92% \n",
      "400 Epochs Accuracy : 97.66% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9531\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 66.41% \n",
      "200 Epochs Accuracy : 96.09% \n",
      "300 Epochs Accuracy : 97.66% \n",
      "400 Epochs Accuracy : 98.83% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 71.09% \n",
      "300 Epochs Accuracy : 93.36% \n",
      "400 Epochs Accuracy : 98.05% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 72.27% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 63.28% \n",
      "300 Epochs Accuracy : 82.42% \n",
      "400 Epochs Accuracy : 97.66% \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 62.11% \n",
      "200 Epochs Accuracy : 93.36% \n",
      "300 Epochs Accuracy : 98.05% \n",
      "400 Epochs Accuracy : 98.44% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9219\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 65.23% \n",
      "200 Epochs Accuracy : 82.03% \n",
      "300 Epochs Accuracy : 96.88% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 88.28% \n",
      "200 Epochs Accuracy : 98.05% \n",
      "300 Epochs Accuracy : 98.83% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 64.06% \n",
      "200 Epochs Accuracy : 98.05% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 62.89% \n",
      "200 Epochs Accuracy : 86.72% \n",
      "300 Epochs Accuracy : 96.88% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 62.50% \n",
      "300 Epochs Accuracy : 63.67% \n",
      "400 Epochs Accuracy : 97.27% \n",
      "2/2 [==============================] - 0s 988us/step - loss: 0.2616 - accuracy: 0.9375\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 62.50% \n",
      "300 Epochs Accuracy : 62.50% \n",
      "400 Epochs Accuracy : 62.50% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9487 - accuracy: 0.0000e+00\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 53.12% \n",
      "200 Epochs Accuracy : 97.66% \n",
      "300 Epochs Accuracy : 98.44% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 86.72% \n",
      "300 Epochs Accuracy : 96.88% \n",
      "400 Epochs Accuracy : 97.27% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 66.80% \n",
      "100 Epochs Accuracy : 69.53% \n",
      "200 Epochs Accuracy : 84.77% \n",
      "300 Epochs Accuracy : 96.09% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 98.44% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9688\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 62.50% \n",
      "200 Epochs Accuracy : 82.81% \n",
      "300 Epochs Accuracy : 97.66% \n",
      "400 Epochs Accuracy : 98.05% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 93.75% \n",
      "200 Epochs Accuracy : 98.05% \n",
      "300 Epochs Accuracy : 98.83% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 68.36% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 54.69% \n",
      "100 Epochs Accuracy : 77.34% \n",
      "200 Epochs Accuracy : 99.22% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 98.44% \n",
      "200 Epochs Accuracy : 99.22% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 100.00% \n",
      "200 Epochs Accuracy : 100.00% \n",
      "300 Epochs Accuracy : 100.00% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 98.05% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 100.00% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9688\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 99.61% \n",
      "200 Epochs Accuracy : 99.22% \n",
      "300 Epochs Accuracy : 100.00% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 99.22% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 98.83% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 53.12% \n",
      "100 Epochs Accuracy : 99.61% \n",
      "200 Epochs Accuracy : 99.61% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2410e-04 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.11% \n",
      "100 Epochs Accuracy : 100.00% \n",
      "200 Epochs Accuracy : 100.00% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 99.61% \n",
      "200 Epochs Accuracy : 99.22% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9688\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 98.83% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 42.58% \n",
      "100 Epochs Accuracy : 98.83% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6795e-04 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 99.22% \n",
      "200 Epochs Accuracy : 99.61% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 100.00% \n",
      "200 Epochs Accuracy : 100.00% \n",
      "300 Epochs Accuracy : 100.00% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 100.00% \n",
      "200 Epochs Accuracy : 100.00% \n",
      "300 Epochs Accuracy : 94.92% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 37.50% \n",
      "100 Epochs Accuracy : 99.22% \n",
      "200 Epochs Accuracy : 98.05% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 98.83% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 99.22% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Epochs Accuracy : 99.61% \n",
      "200 Epochs Accuracy : 99.61% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 99.61% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 46.88% \n",
      "100 Epochs Accuracy : 99.22% \n",
      "200 Epochs Accuracy : 100.00% \n",
      "300 Epochs Accuracy : 100.00% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 99.61% \n",
      "200 Epochs Accuracy : 100.00% \n",
      "300 Epochs Accuracy : 100.00% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9844\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 99.22% \n",
      "200 Epochs Accuracy : 99.22% \n",
      "300 Epochs Accuracy : 99.61% \n",
      "400 Epochs Accuracy : 99.22% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 62.50% \n",
      "100 Epochs Accuracy : 98.83% \n",
      "200 Epochs Accuracy : 98.83% \n",
      "300 Epochs Accuracy : 99.22% \n",
      "400 Epochs Accuracy : 100.00% \n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5294e-04 - accuracy: 1.0000\n",
      "0 Epochs Accuracy : 50.00% \n",
      "100 Epochs Accuracy : 98.75% \n",
      "200 Epochs Accuracy : 99.06% \n",
      "300 Epochs Accuracy : 99.37% \n",
      "400 Epochs Accuracy : 99.37% \n"
     ]
    }
   ],
   "source": [
    "mdClassifier = KerasClassifier(build_fn = ANN_model)\n",
    "GS_model = GridSearchCV(estimator = mdClassifier, param_grid = GridParams, n_jobs = None, cv = None ) #기본적으로 5개 폴드로 나눠짐\n",
    "#n_jobs = none으로 설정후 실행 아니면 cpu에 무리옴\n",
    "GS_result = GS_model.fit(Training_All, Training_All_Label, verbose = 0, epochs = iteration, callbacks = [AccuracyPerEpoch()]) # 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Combination of Hyperparameters : 8\n"
     ]
    }
   ],
   "source": [
    "print('Total Combination of Hyperparameters :', len(GS_model.cv_results_.get('params')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data  = np.array(pd.read_csv('./K_FoldData/Test_Data' , sep=\",\", header=None))\n",
    "Test_Label = np.array(pd.read_csv('./K_FoldData/Test_Label_forANN', sep=\",\", header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters :  {'learningRate': 0.001, 'noOfHiddenLayer': 3, 'noOfNeuron': 8}\n",
      "Best Score : 99.69%\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Best Test Score : 100.0%\n"
     ]
    }
   ],
   "source": [
    "print('Best Hyperparameters : ', GS_model.best_params_) # 최고 검증정확도 하이퍼파라미터\n",
    "print('Best Score : {}%'.format(round(GS_model.best_score_*100, 2)) )\n",
    "\n",
    "# 모델 평가\n",
    "Test_Score = GS_model.score(Test_Data, Test_Label) #베스트 파라미터의 기준으로 점수가 나옴\n",
    "print('Best Test Score : {}%'.format(round(Test_Score*100, 2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learningRate</th>\n",
       "      <th>param_noOfHiddenLayer</th>\n",
       "      <th>param_noOfNeuron</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.447883</td>\n",
       "      <td>0.314109</td>\n",
       "      <td>0.134619</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learningRate': 0.0001, 'noOfHiddenLayer': 2,...</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.375390</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.493420</td>\n",
       "      <td>0.022914</td>\n",
       "      <td>0.125648</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>{'learningRate': 0.0001, 'noOfHiddenLayer': 2,...</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.833713</td>\n",
       "      <td>1.387016</td>\n",
       "      <td>0.177109</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learningRate': 0.0001, 'noOfHiddenLayer': 3,...</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.394493</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.887483</td>\n",
       "      <td>0.369716</td>\n",
       "      <td>0.133902</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>{'learningRate': 0.0001, 'noOfHiddenLayer': 3,...</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.701861</td>\n",
       "      <td>0.637441</td>\n",
       "      <td>0.133549</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learningRate': 0.001, 'noOfHiddenLayer': 2, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.425000</td>\n",
       "      <td>0.132537</td>\n",
       "      <td>0.170703</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>{'learningRate': 0.001, 'noOfHiddenLayer': 2, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.878482</td>\n",
       "      <td>0.415429</td>\n",
       "      <td>0.165557</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learningRate': 0.001, 'noOfHiddenLayer': 3, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.513394</td>\n",
       "      <td>0.532270</td>\n",
       "      <td>0.165659</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>{'learningRate': 0.001, 'noOfHiddenLayer': 3, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.447883      0.314109         0.134619        0.007014   \n",
       "1       3.493420      0.022914         0.125648        0.007798   \n",
       "2       4.833713      1.387016         0.177109        0.042391   \n",
       "3       3.887483      0.369716         0.133902        0.007946   \n",
       "4       3.701861      0.637441         0.133549        0.008694   \n",
       "5       3.425000      0.132537         0.170703        0.054745   \n",
       "6       3.878482      0.415429         0.165557        0.030335   \n",
       "7       4.513394      0.532270         0.165659        0.033616   \n",
       "\n",
       "  param_learningRate param_noOfHiddenLayer param_noOfNeuron  \\\n",
       "0             0.0001                     2                8   \n",
       "1             0.0001                     2               16   \n",
       "2             0.0001                     3                8   \n",
       "3             0.0001                     3               16   \n",
       "4              0.001                     2                8   \n",
       "5              0.001                     2               16   \n",
       "6              0.001                     3                8   \n",
       "7              0.001                     3               16   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learningRate': 0.0001, 'noOfHiddenLayer': 2,...           0.046875   \n",
       "1  {'learningRate': 0.0001, 'noOfHiddenLayer': 2,...           0.921875   \n",
       "2  {'learningRate': 0.0001, 'noOfHiddenLayer': 3,...           0.937500   \n",
       "3  {'learningRate': 0.0001, 'noOfHiddenLayer': 3,...           0.968750   \n",
       "4  {'learningRate': 0.001, 'noOfHiddenLayer': 2, ...           1.000000   \n",
       "5  {'learningRate': 0.001, 'noOfHiddenLayer': 2, ...           1.000000   \n",
       "6  {'learningRate': 0.001, 'noOfHiddenLayer': 3, ...           1.000000   \n",
       "7  {'learningRate': 0.001, 'noOfHiddenLayer': 3, ...           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.953125           0.984375                1.0                1.0   \n",
       "1           0.984375           0.984375                1.0                1.0   \n",
       "2           0.000000           1.000000                1.0                1.0   \n",
       "3           0.984375           1.000000                1.0                1.0   \n",
       "4           0.984375           0.968750                1.0                1.0   \n",
       "5           0.984375           0.968750                1.0                1.0   \n",
       "6           0.984375           1.000000                1.0                1.0   \n",
       "7           0.984375           0.984375                1.0                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.796875        0.375390                7  \n",
       "1         0.978125        0.028980                6  \n",
       "2         0.787500        0.394493                8  \n",
       "3         0.990625        0.012500                3  \n",
       "4         0.990625        0.012500                3  \n",
       "5         0.990625        0.012500                3  \n",
       "6         0.996875        0.006250                1  \n",
       "7         0.993750        0.007655                2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(GS_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean test score 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
